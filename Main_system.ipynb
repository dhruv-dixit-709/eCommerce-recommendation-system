{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import joblib\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset and add headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset and give the column names\n",
    "columns = ['userId', 'productId', 'ratings','timestamp']\n",
    "electronics_df = pd.read_csv('Dataset.csv', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the timestamp column\n",
    "electronics_df.drop('timestamp',\n",
    "                    axis = 1,\n",
    "                    inplace = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows and columns\n",
    "rows, columns = electronics_df.shape\n",
    "print('Number of rows: ', rows)\n",
    "print('Number of columns: ', columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes\n",
    "electronics_df.dtypes\n",
    "\n",
    "#~ Output:\n",
    "    #~ userId        object\n",
    "    #~ productId     object\n",
    "    #~ ratings       float64\n",
    "    #~ dtype:        object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking subset of the dataset\n",
    "electronics_df1 = electronics_df.iloc[:50000,0:]      # Done due to size of Dataset i.e. 374 million columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of rating variable\n",
    "electronics_df1['ratings'].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum ratings\n",
    "print('Minimum rating is: %d' %(electronics_df1.ratings.min()))\n",
    "print('Maximum rating is: %d' %(electronics_df1.ratings.max()))\n",
    "\n",
    "#~ Rating scale is from 1 to 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handelling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Number of missing values across columns: \\n',electronics_df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the rating\n",
    "with sns.axes_style('white'):\n",
    "    g = sns.factorplot(\"ratings\", \n",
    "                       data = electronics_df1, \n",
    "                       aspect = 2.0, \n",
    "                       kind = 'count'\n",
    "                       )\n",
    "    g.set_ylabels(\"Total number of ratings\")\n",
    "\n",
    "#~ Done to see which rating is given by most number of users\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users and Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique user id  in the data\n",
    "print('Number of unique users in Raw data = ', electronics_df1['userId'].nunique())\n",
    "# Number of unique product id  in the data\n",
    "print('Number of unique product in Raw data = ', electronics_df1['productId'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the subset of dataset to reduce density and make it sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the top 10 users based on ratings\n",
    "most_rated = electronics_df1.groupby('userId').size().sort_values(ascending = False)[:10]\n",
    "print('Top 10 users based on ratings: \\n',most_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = electronics_df1.userId.value_counts()\n",
    "electronics_df1_final = electronics_df1[electronics_df1.userId.isin(counts[counts >= 15].index)]\n",
    "print('Number of users who have rated 25 or more items = ', len(electronics_df1_final))\n",
    "print('Number of unique users in the final data = ', electronics_df1_final['userId'].nunique())\n",
    "print('Number of unique products in the final data = ', electronics_df1_final['userId'].nunique())\n",
    "\n",
    "#~ electronics_df1_final has the users who have rated 25 or more different items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rating analysis in the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the pivot table\n",
    "final_ratings_matrix = electronics_df1_final.pivot(index = 'userId', columns = 'productId', values = 'ratings').fillna(0)\n",
    "final_ratings_matrix.head()\n",
    "\n",
    "#~ Will be a sparse matrix if most of the cells are filled with 0 as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of final_ratings_matrix: ', final_ratings_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calucating the density of the rating marix\n",
    "given_num_of_ratings = np.count_nonzero(final_ratings_matrix)\n",
    "print('given_num_of_ratings = ', given_num_of_ratings)\n",
    "possible_num_of_ratings = final_ratings_matrix.shape[0] * final_ratings_matrix.shape[1]\n",
    "print('possible_num_of_ratings = ', possible_num_of_ratings)\n",
    "density = (given_num_of_ratings/possible_num_of_ratings)\n",
    "density *= 100\n",
    "print ('density: {:4.2f}%'.format(density))\n",
    "\n",
    "#~ If density comes out to be less than 20%, then it will be a sparse matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data for TRAINING & TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data randomnly into train and test datasets into 70:30 ratio\n",
    "train_data, test_data = train_test_split(electronics_df1_final, \n",
    "                                         test_size = 0.3, \n",
    "                                         random_state = 0\n",
    "                                         )\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of training data: ', train_data.shape)\n",
    "print('Shape of testing data: ', test_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Popularity Recommender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of user_id for each unique product as recommendation score \n",
    "train_data_grouped = train_data.groupby('productId').agg({'userId': 'count'}).reset_index()\n",
    "train_data_grouped.rename(columns = {'userId': 'score'}, inplace = True)\n",
    "train_data_grouped.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~ Generating the recommendation order\n",
    "\n",
    "# Sort the products on recommendation score \n",
    "train_data_sort = train_data_grouped.sort_values(['score', 'productId'], ascending = [0,1]) \n",
    "      \n",
    "# Generate a recommendation rank based upon score \n",
    "train_data_sort['rank'] = train_data_sort['score'].rank(ascending=0, method='first') \n",
    "          \n",
    "# Get the top 5 recommendations \n",
    "popularity_recommendations = train_data_sort.head(5) \n",
    "popularity_recommendations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity based recommender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id):     \n",
    "    user_recommendations = popularity_recommendations \n",
    "          \n",
    "    # Add user_id column for which the recommendations are being generated \n",
    "    user_recommendations['userId'] = user_id \n",
    "      \n",
    "    # Bring user_id column to the front \n",
    "    cols = user_recommendations.columns.tolist() \n",
    "    cols = cols[-1:] + cols[:-1] \n",
    "    user_recommendations = user_recommendations[cols] \n",
    "          \n",
    "    return user_recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_recom = [10,100,150]   # This list is user choice.\n",
    "for i in find_recom:\n",
    "    print(\"The list of recommendations for the userId: %d\\n\" %(i))\n",
    "    print(recommend(i))    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "#~ Since, it is a Popularity recommender model, so, all the three users are given the same recommendations.\n",
    "#~ Here, we predict the products based on the popularity. It is not personalized to particular user.\n",
    "#~ It is a non-personalized recommender system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Filtering recommender model i.e. User Based Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df_CF = pd.concat([train_data, test_data]).reset_index()\n",
    "electronics_df_CF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix with row per 'user' and column per 'item' \n",
    "pivot_df = electronics_df_CF.pivot(index = 'userId', \n",
    "                                   columns = 'productId', \n",
    "                                   values = 'ratings').fillna(0)\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the pivot table: ', pivot_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user index from 0 to 10\n",
    "pivot_df['user_index'] = np.arange(0, pivot_df.shape[0], 1)\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.set_index(['user_index'], \n",
    "                   inplace = True\n",
    "                   )\n",
    "\n",
    "# Actual ratings given by users\n",
    "pivot_df.head()\n",
    "\n",
    "#~ As this matrix is a sparse matrix, we will be using Singular Value Decomposition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition\n",
    "U, sigma, Vt = svds(pivot_df, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Left singular matrix: \\n',U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sigma: \\n',sigma)\n",
    "#~ As sigma is not a diagonal matrix, we have to convert it into a diagonal one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct diagonal array in SVD\n",
    "sigma = np.diag(sigma)              # Matrix transformation function\n",
    "print('Diagonal matrix: \\n',sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Right singular matrix: \\n',Vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted ratings\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "# Convert predicted ratings to dataframe\n",
    "preds_df = pd.DataFrame(all_user_predicted_ratings, columns = pivot_df.columns)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend the items with the highest predicted ratings\n",
    "\n",
    "def recommend_items(userID, pivot_df, preds_df, num_recommendations):\n",
    "    # index starts at 0  \n",
    "    user_idx = userID-1 \n",
    "    # Get and sort the user's ratings\n",
    "    sorted_user_ratings = pivot_df.iloc[user_idx].sort_values(ascending = False)\n",
    "    # sorted_user_ratings\n",
    "    sorted_user_predictions = preds_df.iloc[user_idx].sort_values(ascending = False)\n",
    "    # sorted_user_predictions\n",
    "    temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis = 1)\n",
    "    temp.index.name = 'Recommended Items'\n",
    "    temp.columns = ['user_ratings', 'user_predictions']\n",
    "    temp = temp.loc[temp.user_ratings == 0]   \n",
    "    temp = temp.sort_values('user_predictions', ascending = False)\n",
    "    \n",
    "    print('\\nBelow are the recommended items for user(user_id = {}):\\n'.format(userID))\n",
    "    print(temp.head(num_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended items for user with user_id = 4\n",
    "userID = 4\n",
    "num_recommendations = 5\n",
    "recommend_items(userID, pivot_df, preds_df, num_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are the recommended items for user with user_id = 6\n",
    "userID = 6\n",
    "num_recommendations = 5\n",
    "recommend_items(userID, pivot_df, preds_df, num_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are the recommended items for user with user_id = 8\n",
    "userID = 8\n",
    "num_recommendations = 5\n",
    "recommend_items(userID, pivot_df, preds_df, num_recommendations)\n",
    "\n",
    "#~ Since, it is a Collaborative recommender model, so, all the three users are given different recommendations based on users past behaviour."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Collabrative recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual ratings given by the users\n",
    "final_ratings_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average ACTUAL rating for each item\n",
    "final_ratings_matrix.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted ratings \n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average PREDICTED rating for each item\n",
    "preds_df.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df = pd.concat([final_ratings_matrix.mean(), preds_df.mean()], axis = 1)\n",
    "rmse_df.columns = ['Avg_actual_ratings', 'Avg_predicted_ratings']\n",
    "print(rmse_df.shape)\n",
    "rmse_df['item_index'] = np.arange(0, rmse_df.shape[0], 1)\n",
    "rmse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = round((((rmse_df.Avg_actual_ratings - rmse_df.Avg_predicted_ratings) ** 2).mean() ** 0.5), 5)\n",
    "print('\\nRMSE SVD Model = {} \\n'.format(RMSE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE SVD Model = 0.05854"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting top - K ( K = 5) recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter 'userID' and 'num_recommendations' for the user\n",
    "userID = 9\n",
    "num_recommendations = 5\n",
    "recommend_items(userID, pivot_df, preds_df, num_recommendations)\n",
    "# Below are the recommended items for user(user_id = 9):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions and Inferences:\n",
    "\n",
    "1. The Popularity-based recommender system is a non-personalised recommender system and these are based on frequecy counts, which may be not suitable to the user. We can see the differance above for the user id 4, 6 & 8, The Popularity based model has recommended the same set of 5 products to both but Collaborative Filtering based model has recommended entire different list based on the user past purchase history.\n",
    "\n",
    "2. Model-based Collaborative Filtering is a personalised recommender system, the recommendations are based on the past behavior of the user and it is not dependent on any additional information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
